{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle-Freesound-audio-tagging\n",
    "\n",
    "https://www.kaggle.com/c/freesound-audio-tagging\n",
    "\n",
    "Решение с небольшим изменением параметров дает 0.8 очков на Public Leaderboard, Ваша задача преодолеть 0.9.\n",
    "\n",
    "\n",
    "Проверьте, что папка с данными лежит по пути `DATADIR`, архивы распакованы.\n",
    "Потестировано на версиях python 2.7/3.5/3.6, tf>=1.4. \n",
    "\n",
    "Код под одну карточку, так что на машинах с несколькими запускайте с ограничениями `CUDA_VISIBLE_DEVICES=x jupyter notebook ...` или модифицируйте код.\n",
    "\n",
    "Более гибкое решение можно описать в файлах (см. README.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # закомментируйте на время отладки\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.contrib.learn.python.learn.learn_io.generator_io import generator_input_fn\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "# сначала проверьте пути\n",
    "DATADIR='/data/kaggle-freesound/'\n",
    "OUTDIR = './runs/'\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTDIR)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)  # закомментируйте на время отладки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем сначала небольшой EDA касательно данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.io import wavfile\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_files = glob(os.path.join(DATADIR, 'audio_train/*wav'))\n",
    "test_files = glob(os.path.join(DATADIR, 'audio_test/*wav'))\n",
    "train_lens = [len(wavfile.read(_)[1]) for _ in tqdm_notebook(train_files)]\n",
    "test_lens = [len(wavfile.read(_)[1]) for _ in tqdm_notebook(test_files)]\n",
    "sns.distplot(train_lens, kde=False, label='train')\n",
    "sns.distplot(test_lens, kde=False, label='test')\n",
    "\n",
    "min(train_lens), min(test_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обратите внимание, что у файлов разная длина. А в тесте есть пустые записи.**\n",
    "\n",
    "Это необходимо будет учесть при написании загрузчика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве простого решения на сетках предлагается нарезать записи на фрагменты одинакового размера, преобразовать их в спектрограммы.\n",
    "Из одномерного сигнала (timesteps, ) получается спектрограмма (time_bins, freq_bins) -- комплекснозначная матрица.\n",
    "Обычный подход -- это выделить модуль и угол комплексных чисел, немного преобразовать и склеить обратно в массив. \n",
    "\n",
    "Аудиозаписи в задаче лежат в формате wav -- это просто одномерные сигналы в формате int16.\n",
    "Для дальнейшей работы их надо будет перевести в float32:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read(fname):\n",
    "    _, wav = wavfile.read(fname)\n",
    "    wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = _read(train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import signal\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(np.float32, [None])\n",
    "\n",
    "# обратите внимание на параметры -- их можно варьировать, получая больше частот.\n",
    "# обратите внимание, что исходные сигналы имеют sampling rate 44100\n",
    "specgram = signal.stft(x, 800, 400)  # [time_bins, freq_bins]\n",
    "\n",
    "phase = tf.angle(specgram) / np.pi  # приводим угол к [-1, 1]\n",
    "amp = tf.log1p(tf.abs(specgram))  # одно из обычных преобразований для амплитуды\n",
    "with tf.Session() as sess:\n",
    "    v, w = sess.run([amp, phase], feed_dict={x: _read(train_files[2])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь среднее вычитается для наглядности картинок\n",
    "plt.figure(figsize=(8, 12))\n",
    "plt.title('amp')\n",
    "sns.heatmap(v - v.mean(axis=0), robust=True, center=0)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 12))\n",
    "plt.title('phase')\n",
    "sns.heatmap(w - w.mean(axis=0), robust=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Угол не выглядит слишком полезным, а на аплитуде мало высоких частот."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, W = [], []\n",
    "with tf.Session() as sess:\n",
    "    for fname in tqdm_notebook(train_files):\n",
    "        v = sess.run(amp, feed_dict={x: _read(fname)})\n",
    "        V.append(np.mean(v, axis=0))\n",
    "        W.append(np.std(v, axis=0))\n",
    "        \n",
    "        \n",
    "V = np.array(V)\n",
    "W = np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.mean(V, axis=0), label='mean amp')\n",
    "plt.plot(np.mean(W, axis=0), label='std amp')\n",
    "\n",
    "plt.xlabel('freq bin')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете перевзвесить спектрограмму так чтобы высокие частоты имели больший вес или просто сместить среднее на посчитанные кривые.\n",
    "\n",
    "Придумывайте гипотезы и экспериментируйте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# прочитаем данные и разобьем выделим трейн и валидацию\n",
    "df = pd.read_csv(os.path.join(DATADIR, 'train.csv'))\n",
    "labels = sorted(set(df.label.values))\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "df['label'] = [label2id[_] for _ in df.label.values]\n",
    "df['fname'] = [\n",
    "    os.path.join(DATADIR, 'audio_train', _) for _ in df.fname.values]\n",
    "\n",
    "# todo: разберитесь с форматом входных данных, потюньте процедуру разбиения\n",
    "# можно добавить фолды, балансировать классы или разбивать по флагу ручной разметки\n",
    "idx = np.arange(len(df))\n",
    "idx_train, idx_val = train_test_split(\n",
    "    idx, test_size=0.33, random_state=2018, shuffle=True)\n",
    "df_train, df_val = df.iloc[idx_train], df.iloc[idx_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# далее займемся сеткой\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Опишем сетку (тушку, body, feature extractor).\n",
    "# На вход приходит _картинка_ размером [?, ?, ?, 2] \n",
    "#  количество частот мы можем менять параметрами stft\n",
    "#  количество шагов по времени зависит от stft и длины самой записи\n",
    "#  канал с углом можно выбросить\n",
    "def baseline(x, params, is_training):\n",
    "    # это общие параметры для сверточных слоев, мы будем передавать их явно:\n",
    "    afn = dict(\n",
    "        normalizer_fn=layers.batch_norm,\n",
    "        normalizer_params=dict(is_training=is_training),\n",
    "    )\n",
    "\n",
    "    # baseline всего на три слоя сверток и пулингов. Поменяйте на свою\n",
    "    for i in range(3):\n",
    "        if is_training:\n",
    "            x = tf.nn.dropout(x, 0.9)\n",
    "        x = layers.conv2d(x, 16 * (2 ** i), (3, 11), **afn)\n",
    "        x = layers.max_pool2d(x, 2, 2)\n",
    "        \n",
    "    # GAP (Global Average Polling) уберет пространственные размерности и оставит только каналы\n",
    "    gap = tf.reduce_mean(x, axis=[1, 2], keep_dims=True)\n",
    "    gap = tf.nn.dropout(gap, params.keep_prob if is_training else 1.0)\n",
    "\n",
    "    # вместо полносвязного слоя удобно взять свертку 1х1 на нужное количество классов\n",
    "    x = tf.layers.conv2d(gap, params.num_classes, 1, activation=None)\n",
    "    # тушка возвращает логиты\n",
    "    return tf.squeeze(x, [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь опишем модельку:\n",
    "#   features -- словарь с входными тензорами, \n",
    "#   labels -- тензор с метками, \n",
    "#   mode -- один из трех вариантов tf.estimator.ModeKeys.TRAIN/EVAL/PREDICT\n",
    "#   params -- набор параметров, который мы сформируем позже\n",
    "#\n",
    "#   функция должна вернуть правильно заполненный tf.estimator.EstimatorSpec(**specs), \n",
    "#     см документацию и комменты в исходном коде, если хотите разобраться глубже\n",
    "\n",
    "def model_handler(features, labels, mode, params, config):\n",
    "    # эта функция делает три разных версии вычислительного графа в зависимости от параметра mode\n",
    "    # общим остается преобразование сигнала в спектрограмму и проход сетки\n",
    "    # в тренировочном варианте к графу добавляются тренировочные вершины\n",
    "    # в валидационном подсчет разных метрик\n",
    "    extractor = tf.make_template(\n",
    "        'extractor', baseline,\n",
    "        create_scope_now_=True,\n",
    "    )\n",
    "\n",
    "    wav = features['wav']  # здесь будет тензор [bs, timesteps]\n",
    "    specgram = signal.stft(wav, 400, 160)  # здесь комплекснозначный тензор [bs, time_bins, freq_bins]\n",
    "\n",
    "    phase = tf.angle(specgram) / np.pi\n",
    "    amp = tf.log1p(tf.abs(specgram))\n",
    "\n",
    "    x = tf.stack([amp, phase], axis=3)  # здесь почти обычная картинка  [bs, time_bins, freq_bins, 2]\n",
    "    x = tf.to_float(x)\n",
    "\n",
    "    logits = extractor(x, params, mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    predictions = tf.nn.softmax(logits)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels=labels, logits=logits)\n",
    "        )\n",
    "\n",
    "        # todo: обязательно попробуйте другие варианты изменния lr\n",
    "        def _learning_rate_decay_fn(learning_rate, global_step):\n",
    "            return tf.train.exponential_decay(\n",
    "                learning_rate, global_step, decay_steps=10000, decay_rate=0.99)\n",
    "\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=params.learning_rate,\n",
    "            optimizer=lambda lr: tf.train.AdamOptimizer(lr),  # оптимизатор точно стоит потюнить\n",
    "            learning_rate_decay_fn=_learning_rate_decay_fn,\n",
    "            clip_gradients=params.clip_gradients,\n",
    "            variables=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        acc, acc_op = tf.metrics.accuracy(labels, tf.argmax(logits, axis=-1))\n",
    "        # см https://www.kaggle.com/c/freesound-audio-tagging#evaluation\n",
    "        # метрика оценки mean average precision at 3 (MAP@3)\n",
    "        map3, map3_op = tf.metrics.sparse_average_precision_at_k(\n",
    "            tf.cast(labels, tf.int64), predictions, 3)\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels=labels, logits=logits)\n",
    "        )\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops={\n",
    "                \"MAP@1\": (acc, acc_op),\n",
    "                \"MAP@3\": (map3, map3_op),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            # здесь можно пробрасывать что угодно\n",
    "            'predictions': predictions,  # весь вектор предсказаний\n",
    "            'top3': tf.nn.top_k(predictions, 3)[1],  # топ-3 метки\n",
    "            'prediction': tf.argmax(predictions, 1),  # топовая метка\n",
    "            'fname': features['fname'],  # имя файла, будет удобно работать во время предсказаний на тесте\n",
    "        }\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "        )\n",
    "    return tf.estimator.EstimatorSpec(**specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим очередную папку для модельки\n",
    "outdir = utils.get_new_model_path(OUTDIR)\n",
    "\n",
    "# собираем вместе параметры\n",
    "params = dict(\n",
    "    outdir=outdir,\n",
    "    seed=2018,\n",
    "    datadir=DATADIR,\n",
    "    batch_size=32,\n",
    "    keep_prob=0.8,\n",
    "    learning_rate=3e-4,\n",
    "    clip_gradients=15.0,\n",
    "    num_classes=len(label2id),\n",
    "    train_steps=10000, # количество шагов в тренировке\n",
    "    signal_len=8000,  # размер фрагмента для классификации\n",
    ")\n",
    "\n",
    "\n",
    "hparams = tf.contrib.training.HParams(**params)\n",
    "# на всякий случай сохраним конфиг и словарь меток в папку с запуском\n",
    "with open(os.path.join(outdir, 'hparams.json'), 'w') as fout:\n",
    "    json.dump(params, fout, indent=2)\n",
    "with open(os.path.join(outdir, 'vocab.json'), 'w') as fout:\n",
    "    json.dump(id2label, fout, indent=2)\n",
    "\n",
    "\n",
    "# опишем функции, поставляющие данные в вычислительный граф\n",
    "# см код в utils.py\n",
    "train_input_fn = generator_input_fn(\n",
    "    x=utils.fast_datagenerator(df_train, hparams, 'train'),\n",
    "    target_key='target',\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=True,\n",
    "    queue_capacity=3 * hparams.batch_size,\n",
    "    num_threads=1,\n",
    ")\n",
    "\n",
    "val_input_fn = generator_input_fn(\n",
    "    x=utils.fast_datagenerator(df_val, hparams, 'val'),\n",
    "    target_key='target',\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=False,\n",
    "    queue_capacity=3 * hparams.batch_size,\n",
    "    num_threads=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.estimator.RunConfig(model_dir=hparams.outdir)\n",
    "\n",
    "est = tf.estimator.Estimator(\n",
    "    model_fn=model_handler,\n",
    "    config=config,\n",
    "    params=hparams,\n",
    ")\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=hparams.train_steps)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=val_input_fn)\n",
    "\n",
    "tf.estimator.train_and_evaluate(est, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите tensorboard и смотрите графики обучения\n",
    "\n",
    "```\n",
    "tensorboard --logdir=./OUTDIR/   # в терминале на сервере\n",
    "ssh -L 6006:localhost:6006 # в терминале у себя на машине\n",
    "```\n",
    "Зайдите браузером на http://localhost:6006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь делаем предсказание.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим данные для теста из sample_submission\n",
    "df = pd.read_csv(os.path.join(DATADIR, 'sample_submission.csv'))\n",
    "df.label = 0\n",
    "df.fname = [os.path.join(DATADIR, 'audio_test', _) for _ in df.fname.values]\n",
    "\n",
    "# predict все равно работает по одному примеру, так что давайте уберем батчи\n",
    "# так мы сможем работать с записями целиком\n",
    "# NB: стоит проверить, правильно ли работает pad_value\n",
    "test_input_fn = generator_input_fn(\n",
    "    x=utils.fast_datagenerator(df, params, 'test'),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_epochs=1,\n",
    "    queue_capacity=hparams.batch_size,\n",
    "    num_threads=1,\n",
    "    pad_value=0.0,\n",
    ")\n",
    "\n",
    "it = est.predict(input_fn=test_input_fn)  # это итератор\n",
    "\n",
    "# идем по датасету и сохраняем вывод сетки\n",
    "submission = dict()\n",
    "for output in tqdm_notebook(it):\n",
    "    path = output['fname'].decode()\n",
    "    fname = os.path.basename(path)\n",
    "    # допускается предсказывать три метки на каждую запись\n",
    "    # см условие задачи и метрику оценки\n",
    "    predicted = \" \".join([id2label[i] for i in output['top3']])\n",
    "    submission[fname] = predicted\n",
    "\n",
    "# записываем в файл результаты\n",
    "submission_path = os.path.join(outdir, 'submission.csv')\n",
    "with open(submission_path, 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, pred in submission.items():\n",
    "        fout.write(\"{},{}\\n\".format(fname, pred))\n",
    "        \n",
    "print('Take you submission: {}'.format(submission_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Модель с окном 8к тиков, тренировкой на 10k шагов показывает 0.4 MAP@3 и дает 0.538 на паблике**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
