{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle-Freesound-audio-tagging\n",
    "\n",
    "https://www.kaggle.com/c/freesound-audio-tagging\n",
    "\n",
    "Решение дает 0.8 очков на Public Leaderboard, Ваша задача преодолеть 0.9.\n",
    "\n",
    "\n",
    "Проверьте, что папка с данными лежит по пути `DATADIR`, архивы распакованы.\n",
    "Потестировано на версиях python 2.7/3.5/3.6, tf>=1.4. \n",
    "\n",
    "Код под одну карточку, так что на машинах с несколькими запускайте с ограничениями `CUDA_VISIBLE_DEVICES=x jupyter notebook ...` или модифицируйте код.\n",
    "\n",
    "Более гибкое решение можно описать в файлах (см. README.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.contrib.learn.python.learn.learn_io.generator_io import generator_input_fn\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# todo: поправить путь\n",
    "DATADIR='~/data/kaggle-freesound/'\n",
    "OUTDIR = './runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# опишем сетку -- feature extractor, на вход она получит _картинку_, \n",
    "# тензор с размерами [?, ?, ?, 2], на выходе выдаст логиты [?, num_classes]\n",
    "# постарайтесь все необходимые параметры передать через params\n",
    "def baseline(x, params, is_training):\n",
    "    # это общие параметры для сверточных слоев, мы будем передавать их явно:\n",
    "    afn = dict(\n",
    "        normalizer_fn=layers.batch_norm,\n",
    "        normalizer_params=dict(is_training=is_training),\n",
    "    )\n",
    "\n",
    "    for i in range(3):\n",
    "        if is_training:\n",
    "            x = tf.nn.dropout(x, 0.9)\n",
    "        x = layers.conv2d(x, 16 * (2 ** i), (3, 11), **afn)\n",
    "        x = layers.max_pool2d(x, 2, 2)\n",
    "\n",
    "    gap = tf.reduce_mean(x, axis=[1, 2], keep_dims=True)\n",
    "    gap = tf.nn.dropout(gap, params.keep_prob if is_training else 1.0)\n",
    "\n",
    "    # вместо полносвязного слоя удобно взять свертку 1х1 на нужное количество классов\n",
    "    x = tf.layers.conv2d(gap, params.num_classes, 1, activation=None)\n",
    "\n",
    "    return tf.squeeze(x, [1, 2])\n",
    "\n",
    "\n",
    "# Опишем модельку:\n",
    "#   features -- словарь с входными тензорами, \n",
    "#   labels -- тензор с метками, \n",
    "#   mode -- один из трех вариантов tf.estimator.ModeKeys.TRAIN/EVAL/PREDICT\n",
    "#   params -- набор параметров, который мы сформируем позже\n",
    "#\n",
    "#   функция должна вернуть правильно заполненный tf.estimator.EstimatorSpec(**specs), \n",
    "#     см документацию и комменты в исходном коде, если хотите разобраться глубже\n",
    "\n",
    "def model_handler(features, labels, mode, params, config):\n",
    "    # todo: добавьте сюда выбор модельки по параметру из params\n",
    "    extractor = tf.make_template(\n",
    "        'extractor', baseline,\n",
    "        create_scope_now_=True,\n",
    "    )\n",
    "\n",
    "    wav = features['wav']  # здесь будет тензор [bs, timesteps]\n",
    "    specgram = signal.stft(wav, 400, 160)  # здесь комплекснозначный тензор [bs, time_bins, freq_bins]\n",
    "\n",
    "    phase = tf.angle(specgram) / np.pi\n",
    "    amp = tf.log1p(tf.abs(specgram))\n",
    "\n",
    "    x = tf.stack([amp, phase], axis=3)  # здесь почти обычная картинка  [bs, time_bins, freq_bins, 2]\n",
    "    x = tf.to_float(x)\n",
    "\n",
    "    logits = extractor(x, params, mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    predictions = tf.nn.softmax(logits)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels=labels, logits=logits)\n",
    "        )\n",
    "\n",
    "        # todo: обязательно попробуйте другие варианты изменния lr\n",
    "        def _learning_rate_decay_fn(learning_rate, global_step):\n",
    "            return tf.train.exponential_decay(\n",
    "                learning_rate, global_step, decay_steps=10000, decay_rate=0.99)\n",
    "\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=params.learning_rate,\n",
    "            optimizer=lambda lr: tf.train.AdamOptimizer(lr),  # оптимизатор точно стоит потюнить\n",
    "            learning_rate_decay_fn=_learning_rate_decay_fn,\n",
    "            clip_gradients=params.clip_gradients,\n",
    "            variables=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        acc, acc_op = tf.metrics.accuracy(labels, tf.argmax(logits, axis=-1))\n",
    "        # см https://www.kaggle.com/c/freesound-audio-tagging#evaluation\n",
    "        # метрика оценки mean average precision at 3 (MAP@3)\n",
    "        # нужно чтобы среди трех топовых предсказаний была правильная метка\n",
    "        map3, map3_op = tf.metrics.sparse_average_precision_at_k(\n",
    "            tf.cast(labels, tf.int64), predictions, 3)\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels=labels, logits=logits)\n",
    "        )\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops={\n",
    "                \"MAP@1\": (acc, acc_op),\n",
    "                \"MAP@3\": (map3, map3_op),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            # здесь можно пробрасывать что угодно\n",
    "            'predictions': predictions,  # весь вектор предсказаний\n",
    "            'top3': tf.nn.top_k(predictions, 3)[1],  # топ-3 метки\n",
    "            'prediction': tf.argmax(predictions, 1),  # топовая метка\n",
    "            'fname': features['fname'],  # имя файла, удобный ход\n",
    "        }\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "        )\n",
    "    return tf.estimator.EstimatorSpec(**specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим очередную папку для модельки\n",
    "outdir = utils.get_new_model_path(OUTDIR)\n",
    "\n",
    "# собираем вместе параметры\n",
    "params = dict(\n",
    "    outdir=outdir,\n",
    "    seed=2018,\n",
    "    datadir=DATADIR,\n",
    "    batch_size=32,\n",
    "    keep_prob=0.8,\n",
    "    learning_rage=0.8,\n",
    "    clip_gradients=15.0,\n",
    "    # todo: придумать, что с классами\n",
    "    num_classes=len(label2id),\n",
    ")\n",
    "\n",
    "\n",
    "hparams = tf.contrib.training.HParams(**params)\n",
    "\n",
    "with open(os.path.join(outdir, 'hparams.json'), 'w') as fout:\n",
    "    json.dump(params, fout, indent=2)\n",
    "with open(os.path.join(outdir, 'vocab.json'), 'w') as fout:\n",
    "    json.dump(id2label, fout, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "# последний этап перед запуском -- организовать входные данные\n",
    "# просто читаем и разбиваем на train/val\n",
    "df = pd.read_csv(os.path.join(DATADIR, 'train.csv'))\n",
    "labels = sorted(set(df.label.values))\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "df['label'] = [label2id[_] for _ in df.label.values]\n",
    "df['fname'] = [\n",
    "    os.path.join(DATADIR, 'audio_train', _) for _ in df.fname.values]\n",
    "\n",
    "# todo: разберитесь с форматом входных данных, потюньте процедуру разбиения\n",
    "# можно добавить фолды, балансировать классы или разбивать по флагу ручной разметки\n",
    "idx = np.arange(len(df))\n",
    "idx_train, idx_val = train_test_split(\n",
    "    idx, test_size=0.33, random_state=2018, shuffle=True)\n",
    "df_train, df_val = df.iloc[idx_train], df.iloc[idx_val]\n",
    "\n",
    "# делаем генератры данных с предварительным чтением всех файлов в память\n",
    "train_input_fn = generator_input_fn(\n",
    "    x=utils.fast_datagenerator(df_train, hparams, 'train'),\n",
    "    target_key='target',\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=True,\n",
    "    queue_capacity=3 * hparams.batch_size,\n",
    "    num_threads=1,\n",
    ")\n",
    "\n",
    "val_input_fn = generator_input_fn(\n",
    "    x=utils.fast_datagenerator(df_val, hparams, 'val'),\n",
    "    target_key='target',\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=False,\n",
    "    queue_capacity=3 * hparams.batch_size,\n",
    "    num_threads=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(model_dir=hparams.outdir)\n",
    "\n",
    "\n",
    "est = tf.estimator.Estimator(\n",
    "    model_fn=model_handler,\n",
    "    config=config,\n",
    "    params=hparams,\n",
    ")\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=val_input_fn)\n",
    "\n",
    "tf.estimator.train_and_evaluate(est, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите tensorboard и смотрите графики обучения\n",
    "\n",
    "```\n",
    "tensorboard --logdir=./OUTDIR/   # в терминале на сервере\n",
    "ssh -L 7007:localhost:6006 # в терминале у себя на машине\n",
    "```\n",
    "Зайдите браузером на http://localhost:6006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь делаем предсказание в modeldir надо указать папку с желаемой моделью\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldir = ...\n",
    "# сделать предсказание\n",
    "with open(os.path.join(args.modeldir, 'hparams.json'), 'r') as fin:\n",
    "    params = json.load(fin)\n",
    "\n",
    "with open(os.path.join(args.modeldir, 'vocab.json'), 'r') as fin:\n",
    "    vocab = json.load(fin)\n",
    "    vocab = {int(k): v for k, v in vocab.items()}\n",
    "    \n",
    "params['model_dir'] = modeldir\n",
    "    \n",
    "hparams = tf.contrib.training.HParams(**params)\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=modeldir, session_config=session_config)\n",
    "\n",
    "# создаем модельку\n",
    "model = base.create_model(config=run_config, hparams=hparams)\n",
    "\n",
    "# готовим данные для теста из sample_submission\n",
    "df = pd.read_csv(os.path.join(args.datadir, 'sample_submission.csv'))\n",
    "df.label = 0\n",
    "df.fname = [\n",
    "    os.path.join(args.datadir, 'audio_test', _)\n",
    "    for _ in df.fname.values]\n",
    "\n",
    "# predict все равно работает по одному примеру, так что давайте уберем батчи\n",
    "# так мы сможем работать с записями целиком\n",
    "# NB: стоит проверить, правильно ли работает pad_value\n",
    "test_input_fn = generator_input_fn(\n",
    "    x=utils.fast_datagenerator(df, params, 'test'),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_epochs=1,\n",
    "    queue_capacity=hparams.batch_size,\n",
    "    num_threads=1,\n",
    "    pad_value=0.0,\n",
    ")\n",
    "\n",
    "it = model.predict(input_fn=test_input_fn)  # это итератор\n",
    "\n",
    "# далее немного грязно, отрефакторите, добавьте информацию о фолдах, если нужно\n",
    "submission = dict()\n",
    "for output in tqdm(it):\n",
    "    path = output['fname'].decode()\n",
    "    fname = os.path.basename(path)\n",
    "    # допускается предсказывать три метки на каждую запись\n",
    "    predicted = \" \".join([vocab[i] for i in output['top3']])\n",
    "    submission[fname] = predicted\n",
    "\n",
    "with open(os.path.join(args.modeldir, 'submission.csv'), 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, pred in submission.items():\n",
    "        fout.write(\"{},{}\\n\".format(fname, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
